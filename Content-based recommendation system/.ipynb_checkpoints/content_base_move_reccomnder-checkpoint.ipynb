{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc50c855-d7db-496c-9a03-4817b04924e1",
   "metadata": {},
   "source": [
    "# Content based filltering book Recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f6f72-68d3-4400-bf9d-dd4ac0875205",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be798eac-c86d-4f92-9861-bca97dc0111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e51bf3a-7140-4d49-9b56-f9c362190559",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(r'D:\\Ai Projects\\Movie Rec System - Content based\\datasets\\tmdb_5000_movies.csv') # 'r' for raw string, o/w use / or \\\\\n",
    "credits = pd.read_csv(r'D:\\Ai Projects\\Movie Rec System - Content based\\datasets\\tmdb_5000_credits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be059f2-b594-4427-9f85-106656b5846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff29bf-663f-45d1-9a1d-b82cd13d351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbd49d-6582-41fa-ba3f-3e94ace21371",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cbc100-d204-464e-9fd8-ce2c1cec6540",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab03e0f-2e15-4f8a-b42f-7d9d3476615d",
   "metadata": {},
   "source": [
    "### Merge movie, credits into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a0b00-4b89-42c2-9ffa-09ecdd8e592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies =movies.merge(credits, on='title')\n",
    "print(movies.shape)\n",
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b972b3e-1bbb-4cc4-8769-1a9a4501030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44befdef-5ca1-4f08-9f7c-84997bf242eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.iloc[0]['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e7e6c-82bb-4b88-a528-1c65ff559edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['original_language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0624a7-e2c3-4672-8143-c6b6336a534e",
   "metadata": {},
   "source": [
    "## Let choose columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e6e19-3ef9-4844-a9c9-1104a67945e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3522e7d7-2407-4acf-b707-4f2c79ee91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']] \n",
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd2db8e-65ca-4a92-bf48-a0618f375c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b3c3f-566d-47a6-93cf-662ace0b7808",
   "metadata": {},
   "source": [
    "## Overview & data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb256841-67b0-4872-8630-fc624886abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8482fb-a860-4a42-adb1-93ddfb655462",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dropna(inplace=True) # Removes any rows (by default) that contain at least one NaN (missing value), apply the change directly to movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807c7ee7-b846-417e-ae4e-9e700cca003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.isnull().sum() # no of nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bce4f7-f439-4fc8-ba03-d56d90d7dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d877d45-537d-4341-8724-cb80efc93fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a1c0a-7126-413c-b20f-f36d69a7aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.iloc[0]['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72432d8f-33ab-4be5-af25-b6b5656cd878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast # to convert string into list\n",
    "\n",
    "def convert(text):\n",
    "    if not isinstance(text, str):\n",
    "        if isinstance(text, list):  \n",
    "            return text\n",
    "        return []\n",
    "        \n",
    "    l = []\n",
    "    for i in ast.literal_eval(text): # safely evaluates a string containing a Python literal into the actual object (\"[...]' ---> [...]\n",
    "        l.append(i['name']) # only name {\"id\": 28, \"name\": \"Action\"}\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d22149-a87f-46f6-80c7-5cf5e66d95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast # to convert string into list\n",
    "\n",
    "def convert_cast(text):\n",
    "    if not isinstance(text, str):\n",
    "        if isinstance(text, list):  \n",
    "            return text\n",
    "        return []\n",
    "        \n",
    "    l = []\n",
    "    counter = 0\n",
    "    for i in ast.literal_eval(text): # safely evaluates a string containing a Python literal into the actual object (\"[...]' ---> [...]\n",
    "        if counter>=3:\n",
    "            break\n",
    "        l.append(i['name']) # only name {\"id\": 28, \"name\": \"Action\"}\n",
    "        counter+=1\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730fc09-eba4-4f94-a682-d6a571dc448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "ast.literal_eval('[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6a443-00b3-40b0-919a-6c1fa45cf186",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(convert) # runs the convert function on every row in the genres column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980f05e-8e83-4fb3-a045-2275a788a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627a00f-dd4c-4747-9ae5-4c27ff29ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.iloc[0]['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe108b5-16c1-4cbd-ae21-b3410d798168",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.iloc[0]['cast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e10cb4-a824-4230-9e37-364a869d195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "movies['cast'] = movies['cast'].apply(convert_cast)\n",
    "\n",
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a7371-7d5f-403d-954c-a8e68a57a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.iloc[0]['crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697497d-725a-491e-b373-053c8063c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch only the directory as job\n",
    "# {\"credit_id\": \"52fe48009251416c750aca23\", \"department\": \"Editing\", \"gender\": 0, \"id\": 1721, \"job\": \"Editor\", \"name\": \"Stephen E. Rivkin\"},\n",
    "\n",
    "def fetch_director(text):\n",
    "    if not isinstance(text, str):\n",
    "        if isinstance(text, list):  \n",
    "            return text\n",
    "        return []\n",
    "        \n",
    "    l = []\n",
    "    for i in ast.literal_eval(text): # safely evaluates a string containing a Python literal into the actual object (\"[...]' ---> [...]\n",
    "        if i['job'] == 'Director':\n",
    "            l.append(i['name']) # only name {\"id\": 28, \"name\": \"Action\"}\n",
    "            break\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8502dcf0-0c3b-43ed-9854-c498a5f6045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d6e6a-8d9a-4ebb-b237-b108f79c97c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.iloc[0]['overview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1231e3b2-5edf-44ce-9536-a32b8087a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['overview'] = movies['overview'].apply(lambda x : x.split()) # seperate each word, put into list\n",
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9d1e4-6427-4c4b-863d-7403b4313116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sam Worthington\n",
    "# SamWorthington\n",
    "\n",
    "# data means each row in passing column\n",
    "def remove_spaces(data):\n",
    "    names = []\n",
    "\n",
    "    for i in data:\n",
    "        names.append(i.replace(\" \", \"\"))\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ca057-6999-4d9e-8770-a147330138fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['cast'] = movies['cast'].apply(remove_spaces)\n",
    "movies['crew'] = movies['crew'].apply(remove_spaces)\n",
    "movies['keywords'] = movies['keywords'].apply(remove_spaces)\n",
    "movies['genres'] = movies['genres'].apply(remove_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1a524-2664-49cb-a581-ef1caac17998",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a47fb-d79e-4492-8432-3746fba9b24f",
   "metadata": {},
   "source": [
    "## creating new column tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f7d31-8dd0-4012-a981-421b0037b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all those columns are lists\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5666b7c2-7b97-4e34-b1c9-1c9b9e959644",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.iloc[0]['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e38f1-f6c7-4fb4-8017-7b1158963c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = movies[['movie_id', 'title', 'tags']].copy() # Keep original movies table intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7534e2bd-3143-49f8-87be-a911a33be114",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2955c11-f32c-4f78-88db-3253a50274c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['tags'] = new_df['tags'].apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98378e73-e952-413b-b88e-4942a40011fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa504d9c-9d82-48dc-8227-194af96d550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.iloc[0]['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c5cc0-d1da-45e8-b0dc-7dde52f279b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['tags'] = new_df['tags'].apply(lambda x : x.lower())\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c90cf0c-5fd0-4cc6-a2d7-62bbae77fc7d",
   "metadata": {},
   "source": [
    "## What is Stemming?\n",
    "    Reduce words to their root/base form.\n",
    "    It’s a rule-based chopping method (not always linguistically correct).\n",
    "\n",
    "    Stemming :\n",
    "        Fast, rule-based, may produce non-words.\n",
    "        societies → societi\n",
    "\n",
    "    Lemmatization (better for NLP):\n",
    "        Uses vocabulary + grammar rules.\n",
    "        Produces real words.\n",
    "        societies → society"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394e045-0e81-47c8-967a-c66fd6e0b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9d009-dab1-4a0f-9d59-1e8ae8d543ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aeee59-8395-40d3-96f7-303a812366b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# dispatched ---> dispatch, following ---> follow , ....\n",
    "\n",
    "\n",
    "def stem(text):\n",
    "    l = []\n",
    "    for i in text.split():   # text is a string but text.split() is a list\n",
    "        l.append(ps.stem(i)) # stem each word\n",
    "\n",
    "    return \" \".join(l) # Join back into one string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785d7b2-f87f-4aeb-a38b-c40e80b1b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['tags'] = new_df['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b9ecf-bd01-482b-84bd-b0033d82ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.iloc[0]['tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2a320-973c-45b9-a751-e28e5fdfc22a",
   "metadata": {},
   "source": [
    "## Scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9726d-96fa-491a-a080-1549896f714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e1333-dee6-4ce3-967e-9c04cc702ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = vectorizer.fit_transform(new_df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2130f9-7243-4b09-885a-91cf849d6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca34b5-b4e8-4ecc-86e2-b8c77ecbbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41d05c-e60c-4dbb-8bd1-70c5032f2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db798f-7dfd-4699-9b34-c7e5c5eca47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966ad51-9b15-4cef-bd06-01d355d4a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70a5be-eaa8-4bd1-8b88-cf967c8636f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed90d22-3935-45bd-9b08-c67071c9d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[new_df['title'] == 'Spider-Man'].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1ad45-c3f3-47a6-8149-28cf311bebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import get_close_matches\n",
    "\n",
    "def reccommend_movie(movie):\n",
    "    \n",
    "    titles = new_df['title'].tolist()\n",
    "    \n",
    "    # Find the closest match (allowing typos / case differences)\n",
    "    matches = get_close_matches(movie, titles, n=1, cutoff=0.6)\n",
    "    \n",
    "    if not matches:\n",
    "        print(f\"No close match found for '{movie}'\")\n",
    "        return\n",
    "    \n",
    "    best_match = matches[0]\n",
    "    index = new_df[new_df['title'] == best_match].index[0]\n",
    "\n",
    "\n",
    "    # index = new_df[new_df['title'] == movie].index[0]\n",
    "    distance = sorted(list(enumerate(similarity[index])), reverse=True, key= lambda x : x[1])\n",
    "\n",
    "    print(f\"\\nResults for: {best_match}\\n\")\n",
    "    for i in distance[1:6]:\n",
    "        print(new_df.iloc[i[0]].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143c13a-612f-4b36-b96d-8609edf9299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reccommend_movie('the drk night risen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ce2bbb-dbe0-4bc7-9660-1de71bae0037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(new_df, open('pkls/movie_list.pkl', 'wb'))\n",
    "pickle.dump(similarity, open('pkls/similarity.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5e706-1f54-4658-aa92-f42c68a5dcbc",
   "metadata": {},
   "source": [
    "## codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0ff44be5-50ed-4321-803e-6e2f621edb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for: The Dark Knight Rises\n",
      "\n",
      "The Dark Knight\n",
      "Batman Returns\n",
      "Batman\n",
      "Batman Forever\n",
      "Batman Begins\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Movie Recommendation System\n",
    "# ===============================\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from difflib import get_close_matches\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Load Data\n",
    "# ===============================\n",
    "movies = pd.read_csv(r'D:\\Ai Projects\\Movie Rec System - Content based\\datasets\\tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv(r'D:\\Ai Projects\\Movie Rec System - Content based\\datasets\\tmdb_5000_credits.csv')\n",
    "\n",
    "# Merge datasets on title\n",
    "movies = movies.merge(credits, on='title')\n",
    "\n",
    "# Keep only useful columns\n",
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
    "\n",
    "# Drop missing values\n",
    "movies.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Data Cleaning Functions\n",
    "# ===============================\n",
    "def convert(text):\n",
    "    \"\"\"Convert JSON string into list of names.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    return [i['name'] for i in ast.literal_eval(text)]\n",
    "\n",
    "\n",
    "def convert_cast(text):\n",
    "    \"\"\"Keep top 3 cast members.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    cast = []\n",
    "    for idx, i in enumerate(ast.literal_eval(text)):\n",
    "        if idx >= 3:\n",
    "            break\n",
    "        cast.append(i['name'])\n",
    "    return cast\n",
    "\n",
    "\n",
    "def fetch_director(text):\n",
    "    \"\"\"Fetch director from crew data.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    for i in ast.literal_eval(text):\n",
    "        if i['job'] == 'Director':\n",
    "            return [i['name']]\n",
    "    return []\n",
    "\n",
    "\n",
    "def remove_spaces(names):\n",
    "    \"\"\"Remove spaces from names (e.g., Sam Worthington → SamWorthington).\"\"\"\n",
    "    return [name.replace(\" \", \"\") for name in names]\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Apply Cleaning\n",
    "# ===============================\n",
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "movies['cast'] = movies['cast'].apply(convert_cast)\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split())\n",
    "\n",
    "# Remove spaces in multi-word names\n",
    "for col in ['cast', 'crew', 'keywords', 'genres']:\n",
    "    movies[col] = movies[col].apply(remove_spaces)\n",
    "\n",
    "# Create tags column\n",
    "movies['tags'] = (\n",
    "    movies['overview']\n",
    "    + movies['genres']\n",
    "    + movies['keywords']\n",
    "    + movies['cast']\n",
    "    + movies['crew']\n",
    ")\n",
    "\n",
    "# New dataframe with essential info\n",
    "new_df = movies[['movie_id', 'title', 'tags']].copy()\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x).lower())\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Text Preprocessing (Stemming)\n",
    "# ===============================\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem(text):\n",
    "    \"\"\"Apply stemming to tags text.\"\"\"\n",
    "    return \" \".join(ps.stem(word) for word in text.split())\n",
    "\n",
    "new_df['tags'] = new_df['tags'].apply(stem)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Vectorization & Similarity\n",
    "# ===============================\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words='english')\n",
    "vector = vectorizer.fit_transform(new_df['tags']).toarray()\n",
    "\n",
    "similarity = cosine_similarity(vector)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Recommendation Function\n",
    "# ===============================\n",
    "def recommend_movie(movie):\n",
    "    titles = new_df['title'].tolist()\n",
    "    matches = get_close_matches(movie, titles, n=1, cutoff=0.6)\n",
    "\n",
    "    if not matches:\n",
    "        print(f\"No close match found for '{movie}'\")\n",
    "        return\n",
    "\n",
    "    best_match = matches[0]\n",
    "    index = new_df[new_df['title'] == best_match].index[0]\n",
    "    distances = sorted(\n",
    "        list(enumerate(similarity[index])),\n",
    "        reverse=True,\n",
    "        key=lambda x: x[1]\n",
    "    )\n",
    "\n",
    "    print(f\"\\nRecommendations for: {best_match}\\n\")\n",
    "    for i in distances[1:6]:\n",
    "        print(new_df.iloc[i[0]].title)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Example Run\n",
    "# ===============================\n",
    "recommend_movie('the drk night risen')\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Save Model\n",
    "# ===============================\n",
    "# os.makedirs('pkls', exist_ok=True)\n",
    "# pickle.dump(new_df, open('pkls/movie_list.pkl', 'wb'))\n",
    "# pickle.dump(similarity, open('pkls/similarity.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee6854e0-2689-4a69-bc24-cb1dcb039f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for: Spider-Man\n",
      "\n",
      "Spider-Man 3\n",
      "Spider-Man 2\n",
      "The Amazing Spider-Man 2\n",
      "Arachnophobia\n",
      "Kick-Ass\n"
     ]
    }
   ],
   "source": [
    "recommend_movie('spidr man')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92cc5cd-6b61-4ab8-ac35-11fbca8e3e02",
   "metadata": {},
   "source": [
    "## ===============================\n",
    "\n",
    "## Movie Recommendation System\n",
    "\n",
    "## ===============================\n",
    "\n",
    "```python\n",
    "import os\n",
    "import ast\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from difflib import get_close_matches\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "* `os` → used to interact with the file system, e.g., create folders (`os.makedirs`).\n",
    "* `ast` → safely converts strings that look like Python lists/dictionaries into actual Python objects.\n",
    "\n",
    "  * Example: `'[{\"id\": 28, \"name\": \"Action\"}]'` → `[{\"id\":28,\"name\":\"Action\"}]`\n",
    "* `pickle` → used to save Python objects to a file and load them later (like your dataframe and similarity matrix).\n",
    "* `numpy` → used for numerical operations (arrays, matrices).\n",
    "* `pandas` → used to handle tabular data (dataframes).\n",
    "* `PorterStemmer` → reduces words to their root form: `\"running\"` → `\"run\"`, `\"loved\"` → `\"love\"`. Helps matching similar words.\n",
    "* `get_close_matches` → finds closest strings from a list (helps with typos in movie names).\n",
    "* `CountVectorizer` → converts text into a numerical matrix (count of words).\n",
    "* `cosine_similarity` → measures similarity between vectors (used to find similar movies).\n",
    "\n",
    "---\n",
    "\n",
    "## ===============================\n",
    "\n",
    "## Load Data\n",
    "\n",
    "## ===============================\n",
    "\n",
    "```python\n",
    "movies = pd.read_csv(r'D:\\Ai Projects\\Movie Rec System - Content based\\datasets\\tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv(r'D:\\Ai Projects\\Movie Rec System - Content based\\datasets\\tmdb_5000_credits.csv')\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "* Reads CSV files containing **movies information** and **credits (cast/crew)** into pandas dataframes.\n",
    "* `r` before the string means *raw string*, so Windows paths don’t need double `\\\\`.\n",
    "\n",
    "```python\n",
    "movies = movies.merge(credits, on='title')\n",
    "```\n",
    "\n",
    "* Combines the two datasets on the **title** column so each row has movie info + credits.\n",
    "\n",
    "```python\n",
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
    "movies.dropna(inplace=True)\n",
    "```\n",
    "\n",
    "* Keeps only the useful columns for recommendation.\n",
    "* Removes rows with missing data (`dropna`).\n",
    "\n",
    "---\n",
    "\n",
    "## ===============================\n",
    "\n",
    "## Data Cleaning Functions\n",
    "\n",
    "## ===============================\n",
    "\n",
    "```python\n",
    "def convert(text):\n",
    "    \"\"\"Convert JSON string into list of names.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    return [i['name'] for i in ast.literal_eval(text)]\n",
    "```\n",
    "\n",
    "* Takes columns like `genres` or `keywords` which are **strings that look like lists of dictionaries**, and converts them into a Python list of names.\n",
    "* Example: `'[{\"id\":28,\"name\":\"Action\"}]'` → `[\"Action\"]`.\n",
    "\n",
    "```python\n",
    "def convert_cast(text):\n",
    "    \"\"\"Keep top 3 cast members.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    cast = []\n",
    "    for idx, i in enumerate(ast.literal_eval(text)):\n",
    "        if idx >= 3:\n",
    "            break\n",
    "        cast.append(i['name'])\n",
    "    return cast\n",
    "```\n",
    "\n",
    "* Keeps only the first **3 actors** from the cast (to reduce noise).\n",
    "\n",
    "```python\n",
    "def fetch_director(text):\n",
    "    \"\"\"Fetch director from crew data.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    for i in ast.literal_eval(text):\n",
    "        if i['job'] == 'Director':\n",
    "            return [i['name']]\n",
    "    return []\n",
    "```\n",
    "\n",
    "* From `crew`, finds **only the director**.\n",
    "\n",
    "```python\n",
    "def remove_spaces(names):\n",
    "    \"\"\"Remove spaces from names (e.g., Sam Worthington → SamWorthington).\"\"\"\n",
    "    return [name.replace(\" \", \"\") for name in names]\n",
    "```\n",
    "\n",
    "* Converts `\"Sam Worthington\"` → `\"SamWorthington\"` so multi-word names don’t break token matching later.\n",
    "\n",
    "---\n",
    "\n",
    "## ===============================\n",
    "\n",
    "## Apply Cleaning\n",
    "\n",
    "## ===============================\n",
    "\n",
    "```python\n",
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "movies['cast'] = movies['cast'].apply(convert_cast)\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "```\n",
    "\n",
    "* Applies all the cleaning functions on the respective columns.\n",
    "* Each row now has clean **lists** of words or names.\n",
    "\n",
    "```python\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split())\n",
    "```\n",
    "\n",
    "* Splits the movie overview into a **list of words** instead of one big string.\n",
    "* Example: `\"A hero saves the world\"` → `[\"A\", \"hero\", \"saves\", \"the\", \"world\"]`.\n",
    "\n",
    "```python\n",
    "for col in ['cast', 'crew', 'keywords', 'genres']:\n",
    "    movies[col] = movies[col].apply(remove_spaces)\n",
    "```\n",
    "\n",
    "* Ensures all multi-word names in these columns have no spaces.\n",
    "\n",
    "```python\n",
    "movies['tags'] = (\n",
    "    movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
    ")\n",
    "```\n",
    "\n",
    "* Combines all features (`overview`, `genres`, `keywords`, `cast`, `crew`) into **one big list called `tags`**.\n",
    "* This will be the main data we use for similarity.\n",
    "\n",
    "```python\n",
    "new_df = movies[['movie_id', 'title', 'tags']].copy()\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x).lower())\n",
    "```\n",
    "\n",
    "* Converts the lists of words into a **single lowercase string**.\n",
    "* Example: `[\"hero\", \"Action\", \"SamWorthington\"]` → `\"hero action samworthington\"`\n",
    "\n",
    "---\n",
    "\n",
    "## ===============================\n",
    "\n",
    "## Text Preprocessing (Stemming)\n",
    "\n",
    "## ===============================\n",
    "\n",
    "```python\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem(text):\n",
    "    return \" \".join(ps.stem(word) for word in text.split())\n",
    "\n",
    "new_df['tags'] = new_df['tags'].apply(stem)\n",
    "```\n",
    "\n",
    "* Stemming reduces words to root forms so similar words match.\n",
    "* Example: `\"loved loving love\"` → `\"love love love\"`\n",
    "\n",
    "---\n",
    "\n",
    "## ===============================\n",
    "\n",
    "## Vectorization & Similarity\n",
    "\n",
    "## ===============================\n",
    "\n",
    "```python\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words='english')\n",
    "vector = vectorizer.fit_transform(new_df['tags']).toarray()\n",
    "```\n",
    "\n",
    "* Converts each movie’s `tags` into a **numerical vector** based on word counts.\n",
    "* `max_features=5000` → only top 5000 frequent words are considered.\n",
    "* `stop_words='english'` → ignores common words like \"the\", \"is\", etc.\n",
    "\n",
    "```python\n",
    "similarity = cosine_similarity(vector)\n",
    "```\n",
    "\n",
    "* Computes similarity between all movies using **cosine similarity** (values 0-1).\n",
    "* Example: if Movie A and Movie B share many words in `tags`, similarity ~1; if unrelated, ~0.\n",
    "\n",
    "---\n",
    "\n",
    "## ===============================\n",
    "\n",
    "## Recommendation Function\n",
    "\n",
    "## ===============================\n",
    "\n",
    "```python\n",
    "def recommend_movie(movie):\n",
    "    titles = new_df['title'].tolist()\n",
    "    matches = get_close_matches(movie, titles, n=1, cutoff=0.6)\n",
    "```\n",
    "\n",
    "* Converts all movie titles into a list.\n",
    "* Uses `get_close_matches` to **handle typos**, e.g., `\"Spider-Men\"` → `\"Spider-Man\"`.\n",
    "\n",
    "```python\n",
    "    if not matches:\n",
    "        print(f\"No close match found for '{movie}'\")\n",
    "        return\n",
    "```\n",
    "\n",
    "* If no match is found, it prints a message and stops.\n",
    "\n",
    "```python\n",
    "    best_match = matches[0]\n",
    "    index = new_df[new_df['title'] == best_match].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x: x[1])\n",
    "```\n",
    "\n",
    "* Finds the index of the best matching movie.\n",
    "* Sorts all other movies by similarity in **descending order**.\n",
    "\n",
    "```python\n",
    "    print(f\"\\nRecommendations for: {best_match}\\n\")\n",
    "    for i in distances[1:6]:\n",
    "        print(new_df.iloc[i[0]].title)\n",
    "```\n",
    "\n",
    "* Prints the **top 5 recommended movies**.\n",
    "* `distances[1:6]` → skip the first one because it’s the movie itself.\n",
    "\n",
    "---\n",
    "\n",
    "## ===============================\n",
    "\n",
    "## Example Run\n",
    "\n",
    "## ===============================\n",
    "\n",
    "```python\n",
    "recommend_movie('the drk night risen')\n",
    "```\n",
    "\n",
    "* Tests your system with a typo in the movie name.\n",
    "* Returns closest match + top 5 recommendations.\n",
    "\n",
    "---\n",
    "\n",
    "## ===============================\n",
    "\n",
    "## Save Model\n",
    "\n",
    "## ===============================\n",
    "\n",
    "```python\n",
    "os.makedirs('pkls', exist_ok=True)\n",
    "pickle.dump(new_df, open('pkls/movie_list.pkl', 'wb'))\n",
    "pickle.dump(similarity, open('pkls/similarity.pkl', 'wb'))\n",
    "```\n",
    "\n",
    "* Creates folder `pkls` if it doesn’t exist.\n",
    "* Saves `new_df` and `similarity` matrix as `.pkl` files.\n",
    "* Later, you can **load these files** and serve recommendations without rebuilding everything.\n",
    "\n",
    "---\n",
    "\n",
    "✅ That’s a full **line-by-line explanation**.\n",
    "\n",
    "* The pipeline is: **Load → Clean → Combine Features → Preprocess → Vectorize → Compute Similarity → Recommend → Save**\n",
    "* Each step is **modular**, so you can later add more features (like director rating, release year, etc.).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078fbd4a-57f5-4927-94c3-874982da64c5",
   "metadata": {},
   "source": [
    "## Actual purpose of pkls, How to do recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c422b3f1-e8fe-46fc-916c-4321d4f61a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for: The Dark Knight Rises\n",
      "- The Dark Knight\n",
      "- Batman Returns\n",
      "- Batman\n",
      "- Batman Forever\n",
      "- Batman Begins\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Load saved recommender\n",
    "# ===============================\n",
    "\n",
    "import pickle\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# Step 1: Load the saved files\n",
    "new_df = pickle.load(open('pkls/movie_list.pkl', 'rb'))\n",
    "similarity = pickle.load(open('pkls/similarity.pkl', 'rb'))\n",
    "\n",
    "# Step 2: Define the recommendation function\n",
    "def recommend_movie(movie):\n",
    "    titles = new_df['title'].tolist()\n",
    "    \n",
    "    # Handle typos\n",
    "    matches = get_close_matches(movie, titles, n=1, cutoff=0.6)\n",
    "    if not matches:\n",
    "        print(f\"No close match found for '{movie}'\")\n",
    "        return\n",
    "    \n",
    "    best_match = matches[0]\n",
    "    index = new_df[new_df['title'] == best_match].index[0]\n",
    "    \n",
    "    # Get similarity scores and sort\n",
    "    distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x: x[1])\n",
    "    \n",
    "    print(f\"\\nRecommendations for: {best_match}\")\n",
    "    for i in distances[1:6]:  # top 5 recommendations\n",
    "        print(\"-\", new_df.iloc[i[0]].title)\n",
    "\n",
    "# Step 3: Make a prediction / get recommendations\n",
    "recommend_movie(\"the drk night risen\")  # Handles typos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8bed8f16-3981-4b4c-a983-641cb6ba228f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for: Spider-Man\n",
      "- Spider-Man 3\n",
      "- Spider-Man 2\n",
      "- The Amazing Spider-Man 2\n",
      "- Arachnophobia\n",
      "- Kick-Ass\n"
     ]
    }
   ],
   "source": [
    "recommend_movie('spidr man')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcafc07e-b3cb-4c09-9932-3d912c1a2f90",
   "metadata": {},
   "source": [
    "# Vectorization & Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e055abc-7d0b-4bc4-b419-681b7894f19f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
